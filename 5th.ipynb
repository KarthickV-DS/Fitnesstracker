{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270ffa69-2a86-4510-89c9-ff39480fc5ec",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from src.features.LearningAlgorithms import ClassificationAlgorithms\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Plot settings\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 5)\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "plt.rcParams[\"lines.linewidth\"] = 2\n",
    "\n",
    "\n",
    "df = pd.read_pickle(\"../data-science-template-main/data/interim/03_data_features.pkl\")\n",
    "# --------------------------------------------------------------\n",
    "# Create a training and test set\n",
    "# --------------------------------------------------------------\n",
    "df_train = df.drop(['Set','participant','category'],axis=1)\n",
    "\n",
    "x = df_train.drop(columns=\"label\",axis = 1)\n",
    "y = df_train['label']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(x,y,test_size=0.20,random_state=42,stratify=y)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Split feature subsets\n",
    "# --------------------------------------------------------------\n",
    "basic_features = [\"acc_x\",\"acc_y\",\"acc_z\",\"gyr_x\",\"gyr_y\",\"gyr_z\"]\n",
    "squared_features = [\"acc_r\",\"gyr_r\"]\n",
    "pca_features = [\"pca_1\",\"pca_2\",\"pca_3\"]\n",
    "time_features = [f for f in df_train.columns if\"_temp_\" in f]\n",
    "freq_features = [f for f in df_train.columns if (\"_freq\" in f) or (\"_pse\" in f)]\n",
    "cluster_features = [\"cluster\"]\n",
    "feature_set_1 = list(set(basic_features))\n",
    "feature_set_2 = list(set(basic_features+squared_features+pca_features))\n",
    "feature_set_3 = list(set(feature_set_2+time_features))\n",
    "feature_set_4 = list(set(feature_set_3+freq_features))\n",
    "\n",
    "selected_features = [\n",
    "    'pca_1', \n",
    "    'acc_z_freq_0.0_Hz_ws_14', \n",
    "    'acc_x_freq_0.0_Hz_ws_14', \n",
    "    'gyr_z_temp_std_ws_5', \n",
    "    'acc_x_pse', \n",
    "    'gyr_r_freq_0.0_Hz_ws_14', \n",
    "    'gyr_z_freq_0.714_Hz_ws_14', \n",
    "    'acc_z_temp_mean_ws_5', \n",
    "    'acc_y_temp_mean_ws_5', \n",
    "    'gyr_x_freq_0.0_Hz_ws_14',\n",
    "]\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Perform forward feature selection using simple decision tree\n",
    "# --------------------------------------------------------------\n",
    "learner  = ClassificationAlgorithms()\n",
    "max_features=10\n",
    "selected_features, ordered_features, ordered_scores = learner.forward_selection(max_features,X_train,y_train)\n",
    "# --------------------------------------------------------------\n",
    "# Grid search for best hyperparameters and model selection\n",
    "# --------------------------------------------------------------\n",
    "possible_feature_sets = [\n",
    "    feature_set_1,\n",
    "    feature_set_2,\n",
    "    feature_set_3,\n",
    "    feature_set_4,\n",
    "    selected_features,]\n",
    "\n",
    "feature_names = [\n",
    "    \"feature_set_1\",\n",
    "    \"feature_set_2\",\n",
    "    \"feature_set_3\",\n",
    "    \"feature_set_4\",\n",
    "    \"Selected Features\",\n",
    "]\n",
    "\n",
    "\n",
    "iterations = 1\n",
    "\n",
    "score_df = pd.DataFrame()\n",
    "\n",
    "for i, f in zip(range(len(possible_feature_sets)), feature_names):\n",
    "    print(\"Feature set:\", i)\n",
    "    selected_train_X = X_train[possible_feature_sets[i]]\n",
    "    selected_test_X = X_test[possible_feature_sets[i]]\n",
    "\n",
    "    # First run non deterministic classifiers to average their score.\n",
    "    performance_test_nn = 0\n",
    "    performance_test_rf = 0\n",
    "\n",
    "    for it in range(0, iterations):\n",
    "        print(\"\\tTraining neural network,\", it)\n",
    "        (\n",
    "            class_train_y,\n",
    "            class_test_y,\n",
    "            class_train_prob_y,\n",
    "            class_test_prob_y,\n",
    "        ) = learner.feedforward_neural_network(\n",
    "            selected_train_X,\n",
    "            y_train,\n",
    "            selected_test_X,\n",
    "            gridsearch=False,\n",
    "        )\n",
    "        performance_test_nn += accuracy_score(y_test, class_test_y)\n",
    "\n",
    "        print(\"\\tTraining random forest,\", it)\n",
    "        (\n",
    "            class_train_y,\n",
    "            class_test_y,\n",
    "            class_train_prob_y,\n",
    "            class_test_prob_y,\n",
    "        ) = learner.random_forest(\n",
    "            selected_train_X, y_train, selected_test_X, gridsearch=True\n",
    "        )\n",
    "        performance_test_rf += accuracy_score(y_test, class_test_y)\n",
    "\n",
    "    performance_test_nn = performance_test_nn / iterations\n",
    "    performance_test_rf = performance_test_rf / iterations\n",
    "\n",
    "    # And we run our deterministic classifiers:\n",
    "    print(\"\\tTraining KNN\")\n",
    "    (\n",
    "        class_train_y,\n",
    "        class_test_y,\n",
    "        class_train_prob_y,\n",
    "        class_test_prob_y,\n",
    "    ) = learner.k_nearest_neighbor(\n",
    "        selected_train_X, y_train, selected_test_X, gridsearch=True\n",
    "    )\n",
    "    performance_test_knn = accuracy_score(y_test, class_test_y)\n",
    "\n",
    "    print(\"\\tTraining decision tree\")\n",
    "    (\n",
    "        class_train_y,\n",
    "        class_test_y,\n",
    "        class_train_prob_y,\n",
    "        class_test_prob_y,\n",
    "    ) = learner.decision_tree(\n",
    "        selected_train_X, y_train, selected_test_X, gridsearch=True\n",
    "    )\n",
    "    performance_test_dt = accuracy_score(y_test, class_test_y)\n",
    "\n",
    "    print(\"\\tTraining naive bayes\")\n",
    "    (\n",
    "        class_train_y,\n",
    "        class_test_y,\n",
    "        class_train_prob_y,\n",
    "        class_test_prob_y,\n",
    "    ) = learner.naive_bayes(selected_train_X, y_train, selected_test_X)\n",
    "\n",
    "    performance_test_nb = accuracy_score(y_test, class_test_y)\n",
    "\n",
    "    # Save results to dataframe\n",
    "    models = [\"NN\", \"RF\", \"KNN\", \"DT\", \"NB\"]\n",
    "    new_scores = pd.DataFrame(\n",
    "        {\n",
    "            \"model\": models,\n",
    "            \"feature_set\": f,\n",
    "            \"accuracy\": [\n",
    "                performance_test_nn,\n",
    "                performance_test_rf,\n",
    "                performance_test_knn,\n",
    "                performance_test_dt,\n",
    "                performance_test_nb,\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "    score_df = pd.concat([score_df, new_scores])\n",
    "\n",
    "print(\"Final Score DataFrame:\")\n",
    "print(score_df)\n",
    "\n",
    "score_df.sort_values(by=\"accuracy\" , ascending=False)\n",
    "plt.rcParams['figure.figsize'] = [10,10]\n",
    "sns.barplot(x = \"model\",y=\"accuracy\",hue=\"feature_set\", data = score_df)\n",
    "plt.ylim(0.7,1)\n",
    "plt.show()\n",
    "\n",
    "(\n",
    "    class_train_y,\n",
    "    class_test_y,\n",
    "    class_train_prob_y,\n",
    "    class_test_prob_y,\n",
    "    )=learner.random_forest(\n",
    "      X_train[feature_set_4], y_train, X_test[feature_set_4], gridsearch=True\n",
    ")\n",
    "\n",
    "#accuracy_score(ytest,class_test_y)\n",
    "\n",
    "classes = class_train_prob_y.columns\n",
    "classes\n",
    "\n",
    "classes = class_train_prob_y.columns\n",
    "cm = confusion_matrix(y_test,class_test_y,labels=classes)\n",
    "# create confusion matrix for cm\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "thresh = cm.max() / 2.0\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(\n",
    "        j,\n",
    "        i,\n",
    "        format(cm[i, j]),\n",
    "        horizontalalignment=\"center\",\n",
    "        color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "    )\n",
    "plt.ylabel(\"True label\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "participant_df = df.drop([\"Set\",\"category\"],axis=1)\n",
    "X_train = participant_df[participant_df['participant']!=\"A\"].drop(\"label\",axis=1)\n",
    "y_train = participant_df[participant_df['participant']!=\"A\"][\"label\"]\n",
    "X_test = participant_df[participant_df['participant']==\"A\"].drop(\"label\",axis=1)\n",
    "y_test = participant_df[participant_df['participant']==\"A\"][\"label\"]\n",
    "\n",
    "classes = class_train_prob_y.columns\n",
    "cm = confusion_matrix(y_test,class_test_y,labels=classes)\n",
    "# create confusion matrix for cm\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "thresh = cm.max() / 2.0\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(\n",
    "        j,\n",
    "        i,\n",
    "        format(cm[i, j]),\n",
    "        horizontalalignment=\"center\",\n",
    "        color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "    )\n",
    "plt.ylabel(\"True label\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "score_df.sort_values(by=\"accuracy\" , ascending=False)\n",
    "plt.rcParams['figure.figsize'] = [10,10]\n",
    "sns.barplot(x = \"model\",y=\"accuracy\",hue=\"feature_set\", data = score_df)\n",
    "plt.ylim(0.7,1)\n",
    "plt.show()\n",
    "\n",
    "(\n",
    "    class_train_y,\n",
    "    class_test_y,\n",
    "    class_train_prob_y,\n",
    "    class_test_prob_y,\n",
    "    )=learner.feedforward_neural_network(\n",
    "      X_train[selected_features], y_train, X_test[selected_features], gridsearch=False\n",
    ")\n",
    "\n",
    "print(accuracy_score(y_test,class_test_y))\n",
    "\n",
    "classes = class_train_prob_y.columns\n",
    "classes\n",
    "\n",
    "\n",
    "participant_df = df.drop([\"Set\",\"category\"],axis=1)\n",
    "X_train = participant_df[participant_df['participant']!=\"A\"].drop(\"label\",axis=1)\n",
    "y_train = participant_df[participant_df['participant']!=\"A\"][\"label\"]\n",
    "X_test = participant_df[participant_df['participant']==\"A\"].drop(\"label\",axis=1)\n",
    "y_test = participant_df[participant_df['participant']==\"A\"][\"label\"]\n",
    "\n",
    "classes = class_train_prob_y.columns\n",
    "cm = confusion_matrix(y_test,class_test_y,labels=classes)\n",
    "# create confusion matrix for cm\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "thresh = cm.max() / 2.0\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(\n",
    "        j,\n",
    "        i,\n",
    "        format(cm[i, j]),\n",
    "        horizontalalignment=\"center\",\n",
    "        color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "    )\n",
    "plt.ylabel(\"True label\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64ef0b3-723f-43ab-bf19-6e99aefc993a",
   "metadata": {},
   "source": [
    "## counting reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a990295a-6ec5-4919-aed5-21d6e6c4a2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from src.features.DataTransformation import LowPassFilter\n",
    "from scipy.signal import argrelextrema\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "\n",
    "# Plot settings\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 5)\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "plt.rcParams[\"lines.linewidth\"] = 2\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Load data\n",
    "# --------------------------------------------------------------\n",
    "df = pd.read_pickle(\"data/processed/data_processed.pkl\")\n",
    "df = df[df['label']!=\"rest\"]\n",
    "\n",
    "acc_r = df['acceleration_x']**2 + df['acceleration_y']**2 + df['acceleration_z']**2\n",
    "gyr_r = df['gyroscope_x']**2 + df['gyroscope_y']**2 + df['gyroscope_z']**2\n",
    "\n",
    "df['acc_r'] = np.sqrt(acc_r)\n",
    "df['gyr_r'] = np.sqrt(gyr_r)\n",
    "df\n",
    "# --------------------------------------------------------------\n",
    "# Split data\n",
    "# --------------------------------------------------------------\n",
    "bench_df = df[df['label']==\"bench\"]\n",
    "row_df = df[df['label']==\"row\"]\n",
    "squat_df = df[df['label']==\"squat\"]\n",
    "dead_df = df[df['label']==\"dead\"]\n",
    "ohp_df = df[df['label']==\"ohp\"]\n",
    "row_df\n",
    "# --------------------------------------------------------------\n",
    "# Visualize data to identify patterns\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "lowpass = LowPassFilter()\n",
    "bench_set = bench_df[bench_df['Set'] == bench_df['Set'].unique()[0]]\n",
    "row_set = row_df[row_df['Set'] == row_df['Set'].unique()[0]]\n",
    "squat_set = squat_df[squat_df['Set'] == squat_df['Set'].unique()[0]]\n",
    "dead_set = dead_df[dead_df['Set'] == dead_df['Set'].unique()[0]]\n",
    "ohp_set = ohp_df[ohp_df['Set'] == ohp_df['Set'].unique()[0]]\n",
    "column = \"acc_r\"\n",
    "lowpass.low_pass_filter(bench_set,col = column , sampling_frequency=5,cutoff_frequency=0.4,order=5)[column+\"_lowpass\"].plot()\n",
    "# --------------------------------------------------------------\n",
    "# Configure LowPassFilter\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "def countrep(dataset, cutoff_freq=0.4, order=10, column=\"acc_r\"):\n",
    "    # Apply the low-pass filter\n",
    "    data = lowpass.low_pass_filter(dataset, col=column, sampling_frequency=5, cutoff_frequency=cutoff_freq, order=order)\n",
    "    \n",
    "    # Find local maxima (peaks)\n",
    "    indexes = argrelextrema(data[column + \"_lowpass\"].values, comparator=np.greater)\n",
    "    peaks = data.iloc[indexes]\n",
    "    \n",
    "    # Plot the filtered signal and highlight the peaks\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.plot(data[f\"{column}_lowpass\"], label=f\"{column}_lowpass\")\n",
    "    plt.plot(peaks[f\"{column}_lowpass\"], \"o\", color=\"red\", label=\"Peaks\")\n",
    "    \n",
    "    # Add labels and title\n",
    "    ax.set_ylabel(f\"{column}_lowpass\")\n",
    "    exercise = dataset[\"label\"].iloc[0].title()\n",
    "    category = dataset[\"category\"].iloc[0].title()\n",
    "    plt.title(f\"{category}, {exercise}: {len(peaks)} Reps\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return len(peaks)\n",
    "\n",
    "countrep(dead_set)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Create benchmark dataframe\n",
    "# --------------------------------------------------------------\n",
    "df['reps'] = df['category'].apply(lambda x:5 if x==\"heavy\" else 10)\n",
    "reps_df = df.groupby([\"Set\",'category',\"label\"])['reps'].max().reset_index()\n",
    "reps_df['rep_pred'] = 0  \n",
    "\n",
    "for s in df['Set'].unique():\n",
    "    subset = df[df['Set']==s]\n",
    "    column = \"acc_r\"\n",
    "    cutoff = 0.4\n",
    "\n",
    "    if subset['label'].iloc[0]==\"Squat\":\n",
    "        cutoff = 0.35\n",
    "    elif subset['label'].iloc[0]==\"row\":\n",
    "        cutoff = 0.65\n",
    "        col = \"gyr_x\"\n",
    "    if subset['label'].iloc[0]==\"ohp\":\n",
    "        cutoff = 0.35\n",
    "\n",
    "    reps = countrep(subset,column=column , cutoff_freq=cutoff)\n",
    "\n",
    "    reps_df.loc[reps_df['Set']==s , \"rep_pred\"] = reps\n",
    "\n",
    "reps_df\n",
    "# --------------------------------------------------------------\n",
    "# Evaluate the results\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "error = mean_absolute_error(reps_df['reps'] , reps_df['rep_pred']).round(2)\n",
    "reps_df.groupby([\"label\", \"category\"])[[\"reps\", \"rep_pred\"]].mean().plot.bar()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
